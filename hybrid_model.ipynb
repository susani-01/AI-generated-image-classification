{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "155a2952-2fe7-4a3e-8391-8c9cc36395d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras                    \n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import shutil\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e51be650-fb1e-44e3-9377-771bac15382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/Users/tony/Documents/research_projects/aiGenerated/dataset/train\"\n",
    "test_data_dir = \"/Users/tony/Documents/research_projects/aiGenerated/dataset/archive-2/real_vs_fake/real-vs-fake/testF\"\n",
    "validation_data_dir =\"/Users/tony/Documents/research_projects/aiGenerated/dataset/validation\"\n",
    "IMG_WIDTH,IMG_HEIGHT = 256,256\n",
    "input_shape = (IMG_WIDTH,IMG_HEIGHT,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8364c-001f-4ae6-bce0-d77b1862647a",
   "metadata": {},
   "source": [
    "# *Data augmentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91ed26ea-42e9-407f-8329-6fb458808b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#data generator for RGB images\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "batch_size = 32\n",
    "\n",
    "#Define data generators for RGB images with augmentations\n",
    "datagen_augmented = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    brightness_range = [0.8, 1.2],\n",
    "    preprocessing_function = lambda img: img + np.random.normal(loc=0.0, scale=0.05, size=img.shape),\n",
    "\n",
    "    fill_mode = \"reflect\"\n",
    "    \n",
    ")\n",
    "train_generator = datagen_augmented.flow_from_directory(\n",
    "    train_data_dir, \n",
    "    target_size=(IMG_WIDTH,IMG_HEIGHT),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42, \n",
    "    subset='training',\n",
    ")\n",
    "\n",
    "test_generator = datagen_augmented.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = (IMG_WIDTH,IMG_HEIGHT),\n",
    "    batch_size = 4,\n",
    "    class_mode ='categorical',\n",
    "    shuffle = False,\n",
    "    \n",
    ")\n",
    "validation_generator = datagen_augmented.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size = (IMG_WIDTH,IMG_HEIGHT),\n",
    "    batch_size = 16,\n",
    "    shuffle = True,\n",
    "    seed = 42,\n",
    "    class_mode = 'categorical'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb79a29-6fe5-4db3-a61e-528a5de68790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FAKE': 0, 'REAL': 1}\n"
     ]
    }
   ],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "print(class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18593bf-17ed-4460-9d53-98dd9989091e",
   "metadata": {},
   "source": [
    "# *No of images for each class in the training dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65509341-9584-44c3-a00e-8d4d644ea011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: REAL,Number of images: 45000\n",
      "class: FAKE,Number of images: 45000\n"
     ]
    }
   ],
   "source": [
    "#No of images for each class in the training dataset\n",
    "classes = [class_name for class_name in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir,class_name))]\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(train_data_dir,class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"class: {class_name},Number of images: {num_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c12680-b151-48ff-bdaa-8a7144ef2863",
   "metadata": {},
   "source": [
    "# *Shape of the images in Train Generator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196bbe17-7211-4581-8a87-4b0d508d4802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 2 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 3 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 4 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 5 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 6 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 7 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 8 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 9 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 10 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 11 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 12 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 13 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 14 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 15 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 16 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 17 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 18 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 19 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 20 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 21 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 22 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 23 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 24 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 25 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 26 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 27 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 28 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 29 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 30 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 31 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 32 - Shape: 32x32x3,label: [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "#get a batch of images and labels from the train_generator\n",
    "batch = train_generator.__next__()\n",
    "\n",
    "#Iterate throug the batch to check image shapes\n",
    "for i in range(len(batch[0])):\n",
    "    img = batch[0][i]\n",
    "    label = batch[1][i]\n",
    "\n",
    "    #Get image shape and channels\n",
    "    height,width,channels = img.shape\n",
    "\n",
    "    #Display image shape and channels\n",
    "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels},label: {label}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950ae2a-437d-4fd1-bd36-22cbb2413b2e",
   "metadata": {},
   "source": [
    "# *Number of images in test generator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6888f597-d611-40a2-94fe-9d1cbdbcb8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: real,Number of images: 10000\n",
      "Class: fake,Number of images: 10000\n"
     ]
    }
   ],
   "source": [
    "classes  = [class_name for class_name in os.listdir(test_data_dir) if os.path.isdir(os.path.join(test_data_dir,class_name))]\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(test_data_dir,class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Class: {class_name},Number of images: {num_images}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21f9da3-03d1-495a-bb34-b2485fcb8b55",
   "metadata": {},
   "source": [
    "# *Shape of the images in test generator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1c0a97a-e108-4e87-af5b-b1e39d9e6f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 - Shape: 256x256x3,label: [1. 0.]\n",
      "Image 2 - Shape: 256x256x3,label: [1. 0.]\n",
      "Image 3 - Shape: 256x256x3,label: [1. 0.]\n",
      "Image 4 - Shape: 256x256x3,label: [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "#get a batch of images and labels from the train_generator \n",
    "batch = test_generator.__next__()\n",
    "\n",
    "for i in range(len(batch[0])):\n",
    "    img = batch[0][i] #Image data\n",
    "    label = batch[1][i] #image label\n",
    "\n",
    "    height,width,channels = img.shape\n",
    "\n",
    "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels},label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66b1232f-66d2-4307-b4ef-be2c1bbc5e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: REAL,Number of images: 10000\n",
      "Class: FAKE,Number of images: 10000\n"
     ]
    }
   ],
   "source": [
    "classes  = [class_name for class_name in os.listdir(validation_data_dir) if os.path.isdir(os.path.join(test_data_dir,class_name))]\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(test_data_dir,class_name)\n",
    "    num_images = len(os.listdir(class_path))\n",
    "    print(f\"Class: {class_name},Number of images: {num_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c56030e-a9f9-4cb1-b347-1434eb979d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 2 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 3 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 4 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 5 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 6 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 7 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 8 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 9 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 10 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 11 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 12 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 13 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 14 - Shape: 32x32x3,label: [0. 1.]\n",
      "Image 15 - Shape: 32x32x3,label: [1. 0.]\n",
      "Image 16 - Shape: 32x32x3,label: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#get a batch of images and labels from the train_generator \n",
    "batch = validation_generator.__next__()\n",
    "\n",
    "for i in range(len(batch[0])):\n",
    "    img = batch[0][i] #Image data\n",
    "    label = batch[1][i] #image label\n",
    "\n",
    "    height,width,channels = img.shape\n",
    "\n",
    "    print(f\"Image {i+1} - Shape: {width}x{height}x{channels},label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f16b8-b27f-4af1-a012-d6cf2212aa86",
   "metadata": {},
   "source": [
    "# *check for GPU availability*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776b60cf-19e6-4376-b513-26d733938eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device configured\n"
     ]
    }
   ],
   "source": [
    "#Check for GPU availability\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(tf.config.list_physical_devices ('GPU')[0],True)\n",
    "    print(\"GPU device configured\")\n",
    "else:\n",
    "    print(\"No GPU device found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea80d4c-c198-45e4-b57f-807527a2028f",
   "metadata": {},
   "source": [
    "# *Model Checkpoint*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42445f81-2dcc-4e27-a86c-e7c94e4add6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/Users/tony/Documents/research_projects/aiGenerated/model/checkpoints6\"\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "checkpoint_filename = \"cp.weights.h5\"\n",
    "checkpoint_path = os.path.join(model_dir,checkpoint_filename)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
    "                                                 save_weights_only = True,\n",
    "                                                 save_best_only = True,\n",
    "                                                 monitor = \"val_accuracy\",\n",
    "                                                 mode = \"max\",\n",
    "                                                 verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ddc3129-3e4a-437d-89cc-ca3cfbe6b2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tony/Documents/research_projects/aiGenerated/model/checkpoints6/cp.weights.h5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b0f172-604a-484e-b979-894e3bdca42d",
   "metadata": {},
   "source": [
    "# *MODEL DESIGN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8f1952c-45c2-4793-b92c-732131044edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ leaky_re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_12… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ leaky_re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_13… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ reshape_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │                   │            │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │        \u001b[38;5;34m896\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ leaky_re_lu_12[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_12… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m73,856\u001b[0m │ dropout_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │        \u001b[38;5;34m512\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │    \u001b[38;5;34m295,168\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m1,024\u001b[0m │ leaky_re_lu_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_13… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m65,792\u001b[0m │ reshape_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,051,904\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │                   │            │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m256\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m65,792\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dense_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │        \u001b[38;5;34m514\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,575,362</span> (6.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,575,362\u001b[0m (6.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,402</span> (6.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,574,402\u001b[0m (6.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hybrid_cnn_transformer(input_shape = (256,256,3)):\n",
    "    inputs  = keras.Input(shape = input_shape)\n",
    "\n",
    "    #CNN Features Extraction\n",
    "    x = layers.Conv2D(32,(3,3),activation = \"relu\",padding = \"same\",kernel_regularizer = regularizers.l2(1e-4))(inputs)\n",
    "    #x = layers.LeakyReLU(negative_slope=0.1)(x)#new relu\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(64,(3,3),activation = \"relu\",padding = \"same\",kernel_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.1)(x)#new\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Dropout(0.4)(x) #new dropout\n",
    "\n",
    "    x = layers.Conv2D(128,(3,3),activation = \"relu\",padding = \"same\",kernel_regularizer = regularizers.l2(1e-4))(x)\n",
    "    #x = layers.LeakyReLU(negative_slope=0.1)(x)#new\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(256,(3,3),activation = \"relu\",padding = \"same\",kernel_regularizer = regularizers.l2(1e-4))(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.1)(x)#new relu\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)\n",
    "    x = layers.Dropout(0.4)(x)#new dropi\n",
    "\n",
    "    patches = layers.Reshape((-1,256))(x)\n",
    "    patches = layers.Dense(256,kernel_initializer = \"glorot_uniform\")(patches)\n",
    "\n",
    "    #Transformer block 1\n",
    "    norm_patches = layers.LayerNormalization()(patches)\n",
    "    transformer_layer = layers.MultiHeadAttention(num_heads = 8,key_dim = 128,dropout=0.3)(norm_patches,norm_patches)\n",
    "    transformer_layer = layers.Add()([transformer_layer,patches]) #residual connection\n",
    "    transformer_layer = layers.LayerNormalization()(transformer_layer)\n",
    "    transformer_layer = layers.Dense(256,activation = \"relu\",kernel_regularizer = regularizers.l2(1e-4))(transformer_layer)\n",
    "    transformer_layer = layers.Dropout(0.4)(transformer_layer)\n",
    "\n",
    "    #Transformer block 2\n",
    "    \"\"\"norm_transformer = layers.LayerNormalization()(transformer_layer)\n",
    "    transformer_layer = layers.MultiHeadAttention(num_heads=8,key_dim = 128,dropout = 0.3)(norm_transformer,norm_transformer)\n",
    "    transformer_layer = layers.Add()([transformer_layer,norm_transformer])\n",
    "    transformer_layer = layers.Dense(256,activation = \"relu\",kernel_regularizer=regularizers.l2(1e-4))(transformer_layer)\n",
    "    transformer_layer = layers.Dropout(0.4)(transformer_layer)\"\"\"\n",
    "\n",
    "    #classification Head\n",
    "    features = layers.GlobalAveragePooling1D()(transformer_layer)\n",
    "    features = layers.Dropout(0.4)(features)\n",
    "    outputs = layers.Dense(2,activation = \"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs,outputs)\n",
    "    # model.compile(\n",
    "    #     optimizer=Adam(learning_rate=0.0001,clipnorm = 1.0),\n",
    "    #     loss = \"categorical_crossentropy\",\n",
    "    #     metrics = [\"accuracy\"]\n",
    "        \n",
    "    # )\n",
    "    return model\n",
    "\n",
    "model = hybrid_cnn_transformer()\n",
    "model.summary()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c878f82-08d9-49ce-aded-e3c85fca71dc",
   "metadata": {},
   "source": [
    "# *Training start here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "687469da-4c25-434f-92c8-8547e7f41d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lr_schedule = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6\n",
    ")\"\"\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
    "    #ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-4)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff04bcd0-9cf2-4b6a-97bd-f3a8cdd5d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2025-02-12 09:01:33.892463: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7575 - loss: 0.5641  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.85530, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 56ms/step - accuracy: 0.7575 - loss: 0.5640 - val_accuracy: 0.8553 - val_loss: 0.4062\n",
      "Epoch 2/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8073 - loss: 0.5742  \n",
      "Epoch 2: val_accuracy improved from 0.85530 to 0.87130, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 56ms/step - accuracy: 0.8072 - loss: 0.5742 - val_accuracy: 0.8713 - val_loss: 0.4162\n",
      "Epoch 3/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8217 - loss: 0.5624  \n",
      "Epoch 3: val_accuracy did not improve from 0.87130\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 58ms/step - accuracy: 0.8217 - loss: 0.5624 - val_accuracy: 0.8588 - val_loss: 0.4176\n",
      "Epoch 4/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8496 - loss: 0.4404  \n",
      "Epoch 4: val_accuracy improved from 0.87130 to 0.88530, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 57ms/step - accuracy: 0.8496 - loss: 0.4404 - val_accuracy: 0.8853 - val_loss: 0.3634\n",
      "Epoch 5/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8656 - loss: 0.4084  \n",
      "Epoch 5: val_accuracy improved from 0.88530 to 0.89400, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 56ms/step - accuracy: 0.8656 - loss: 0.4084 - val_accuracy: 0.8940 - val_loss: 0.3522\n",
      "Epoch 6/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8763 - loss: 0.3883  \n",
      "Epoch 6: val_accuracy improved from 0.89400 to 0.89800, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 56ms/step - accuracy: 0.8763 - loss: 0.3883 - val_accuracy: 0.8980 - val_loss: 0.3474\n",
      "Epoch 7/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8848 - loss: 0.3719  \n",
      "Epoch 7: val_accuracy did not improve from 0.89800\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 58ms/step - accuracy: 0.8848 - loss: 0.3719 - val_accuracy: 0.8735 - val_loss: 0.3857\n",
      "Epoch 8/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8889 - loss: 0.3578  \n",
      "Epoch 8: val_accuracy did not improve from 0.89800\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 57ms/step - accuracy: 0.8889 - loss: 0.3578 - val_accuracy: 0.8959 - val_loss: 0.3504\n",
      "Epoch 9/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8939 - loss: 0.3432  \n",
      "Epoch 9: val_accuracy improved from 0.89800 to 0.90220, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 58ms/step - accuracy: 0.8939 - loss: 0.3432 - val_accuracy: 0.9022 - val_loss: 0.3217\n",
      "Epoch 10/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8931 - loss: 0.3399  \n",
      "Epoch 10: val_accuracy did not improve from 0.90220\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 58ms/step - accuracy: 0.8931 - loss: 0.3399 - val_accuracy: 0.9010 - val_loss: 0.3115\n",
      "Epoch 11/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8968 - loss: 0.3305  \n",
      "Epoch 11: val_accuracy improved from 0.90220 to 0.90390, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 57ms/step - accuracy: 0.8968 - loss: 0.3305 - val_accuracy: 0.9039 - val_loss: 0.3104\n",
      "Epoch 12/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8971 - loss: 0.3313  \n",
      "Epoch 12: val_accuracy did not improve from 0.90390\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 60ms/step - accuracy: 0.8971 - loss: 0.3313 - val_accuracy: 0.8874 - val_loss: 0.3624\n",
      "Epoch 13/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8959 - loss: 0.3353  \n",
      "Epoch 13: val_accuracy improved from 0.90390 to 0.91030, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 58ms/step - accuracy: 0.8959 - loss: 0.3353 - val_accuracy: 0.9103 - val_loss: 0.3013\n",
      "Epoch 14/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8983 - loss: 0.3288  \n",
      "Epoch 14: val_accuracy improved from 0.91030 to 0.91560, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 57ms/step - accuracy: 0.8983 - loss: 0.3288 - val_accuracy: 0.9156 - val_loss: 0.2956\n",
      "Epoch 15/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8940 - loss: 0.3394  \n",
      "Epoch 15: val_accuracy did not improve from 0.91560\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 58ms/step - accuracy: 0.8940 - loss: 0.3394 - val_accuracy: 0.9060 - val_loss: 0.3270\n",
      "Epoch 16/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8982 - loss: 0.3356  \n",
      "Epoch 16: val_accuracy did not improve from 0.91560\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 57ms/step - accuracy: 0.8982 - loss: 0.3356 - val_accuracy: 0.9081 - val_loss: 0.3142\n",
      "Epoch 17/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8982 - loss: 0.3355  \n",
      "Epoch 17: val_accuracy did not improve from 0.91560\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 57ms/step - accuracy: 0.8982 - loss: 0.3355 - val_accuracy: 0.9146 - val_loss: 0.2917\n",
      "Epoch 18/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9003 - loss: 0.3285  \n",
      "Epoch 18: val_accuracy improved from 0.91560 to 0.91860, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 57ms/step - accuracy: 0.9003 - loss: 0.3285 - val_accuracy: 0.9186 - val_loss: 0.2823\n",
      "Epoch 19/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9025 - loss: 0.3287  \n",
      "Epoch 19: val_accuracy did not improve from 0.91860\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 56ms/step - accuracy: 0.9025 - loss: 0.3287 - val_accuracy: 0.9076 - val_loss: 0.3304\n",
      "Epoch 20/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8985 - loss: 0.3401  \n",
      "Epoch 20: val_accuracy did not improve from 0.91860\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 55ms/step - accuracy: 0.8985 - loss: 0.3401 - val_accuracy: 0.9142 - val_loss: 0.3127\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = 20,\n",
    "    validation_data = validation_generator,\n",
    "    callbacks = [callbacks,cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabfc29e-8377-4692-825f-c7d6f324d2b1",
   "metadata": {},
   "source": [
    "# *saved history model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21510025-e75a-4e55-a7cc-084d3a67980c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the training history\u001b[39;00m\n\u001b[1;32m      2\u001b[0m initial_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# or the actual initial epoch of the first training session\u001b[39;00m\n\u001b[1;32m      3\u001b[0m saved_history \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Add other metrics as needed\u001b[39;00m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/tony/Documents/research_projects/aiGenerated/model/model_history.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, saved_history)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the training history\n",
    "initial_epoch = 0  # or the actual initial epoch of the first training session\n",
    "saved_history = {\n",
    "    'loss': history.history['loss'],\n",
    "    'accuracy': history.history['accuracy'],\n",
    "    'val_loss': history.history['val_loss'],\n",
    "    'val_accuracy': history.history['val_accuracy'],\n",
    "    # Add other metrics as needed\n",
    "}\n",
    "np.save(\"/Users/tony/Documents/research_projects/aiGenerated/model/model_history.npy\", saved_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "134e280b-8b90-4497-acc7-e5eedd7cb008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(history.history).to_csv(\"/Users/tony/Documents/research_projects/aiGenerated/model/epoch.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e8bf8c-74c7-4947-8410-0de5bf8ecebe",
   "metadata": {},
   "source": [
    "# *Testing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c8f6a20-cb7b-4881-8551-9c904af8fd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = hybrid_cnn_transformer()\n",
    "\n",
    "checkpoint_path = \"/Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\"\n",
    "\n",
    "try:\n",
    "    model.load_weights(checkpoint_path)\n",
    "    print(\"weights loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load weights. Error{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb91b1d-f64f-4de0-9cd4-5705c70793cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22c78264-97f0-4ffa-846e-969b38222638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1099s\u001b[0m 219ms/step\n",
      "Predidcted classes: [0 0 0 0 0 1 0 0 0 1]\n",
      "True classes: [1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the test\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions,axis =1)\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "print(\"Predidcted classes:\",predicted_classes[-10:])\n",
    "print(\"True classes:\",true_classes[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d56224a6-4f29-4006-86de-5987fbe037f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4854\n",
      "Precision: 0.4794089999368731\n",
      "Recall: 0.4450327416123456\n",
      "Jaccard Score 0.2982290482375963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, log_loss, jaccard_score\n",
    "print(f\"Accuracy: {accuracy_score(true_classes,predicted_classes)}\")\n",
    "print(f\"Precision: {precision_score(true_classes,predicted_classes,average = \"weighted\")}\")\n",
    "print(f\"Recall: {f1_score(true_classes,predicted_classes,average = \"weighted\")}\")\n",
    "print(f\"Jaccard Score {jaccard_score(true_classes,predicted_classes,average=\"weighted\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2ac1d-2098-4c98-b641-55c33b5605e5",
   "metadata": {},
   "source": [
    "# *Retraining the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4903de-6884-4c63-805b-570764cb9a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1b15a78-a7bd-466b-af4a-db7bf54a45e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfreezing layer: dense_11\n",
      "Unfreezing layer: dropout_19\n",
      "Unfreezing layer: global_average_pooling1d_3\n",
      "Unfreezing layer: dropout_18\n",
      "Unfreezing layer: dense_10\n",
      "Unfreezing layer: layer_normalization_7\n",
      "Unfreezing layer: add_3\n",
      "Unfreezing layer: multi_head_attention_3\n",
      "Unfreezing layer: layer_normalization_6\n",
      "Unfreezing layer: dense_9\n",
      "Unfreezing layer: reshape_3\n",
      "Unfreezing layer: dropout_16\n",
      "Unfreezing layer: max_pooling2d_7\n",
      "Unfreezing layer: batch_normalization_15\n",
      "Unfreezing layer: leaky_re_lu_7\n",
      "Unfreezing layer: conv2d_15\n",
      "Unfreezing layer: batch_normalization_14\n",
      "Unfreezing layer: conv2d_14\n",
      "Unfreezing layer: dropout_15\n",
      "Unfreezing layer: max_pooling2d_6\n",
      "Unfreezing layer: batch_normalization_13\n",
      "Unfreezing layer: leaky_re_lu_6\n",
      "Unfreezing layer: conv2d_13\n",
      "Unfreezing layer: batch_normalization_12\n",
      "Unfreezing layer: conv2d_12\n",
      "Unfreezing layer: input_layer_3\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9106 - loss: 0.3053  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.92470, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints6/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 57ms/step - accuracy: 0.9106 - loss: 0.3053 - val_accuracy: 0.9247 - val_loss: 0.2738\n",
      "Epoch 2/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9138 - loss: 0.2981  \n",
      "Epoch 2: val_accuracy improved from 0.92470 to 0.92570, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints6/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 56ms/step - accuracy: 0.9138 - loss: 0.2981 - val_accuracy: 0.9257 - val_loss: 0.2672\n",
      "Epoch 3/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9131 - loss: 0.2969  \n",
      "Epoch 3: val_accuracy did not improve from 0.92570\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 58ms/step - accuracy: 0.9131 - loss: 0.2969 - val_accuracy: 0.9255 - val_loss: 0.2661\n",
      "Epoch 4/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9151 - loss: 0.2920  \n",
      "Epoch 4: val_accuracy did not improve from 0.92570\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 53ms/step - accuracy: 0.9151 - loss: 0.2920 - val_accuracy: 0.9240 - val_loss: 0.2732\n",
      "Epoch 5/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9152 - loss: 0.2932  \n",
      "Epoch 5: val_accuracy improved from 0.92570 to 0.92670, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints6/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 55ms/step - accuracy: 0.9152 - loss: 0.2932 - val_accuracy: 0.9267 - val_loss: 0.2697\n",
      "Epoch 6/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9128 - loss: 0.3004  \n",
      "Epoch 6: val_accuracy improved from 0.92670 to 0.93470, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints6/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 55ms/step - accuracy: 0.9128 - loss: 0.3004 - val_accuracy: 0.9347 - val_loss: 0.2614\n",
      "Epoch 7/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9140 - loss: 0.2983  \n",
      "Epoch 7: val_accuracy did not improve from 0.93470\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 55ms/step - accuracy: 0.9140 - loss: 0.2983 - val_accuracy: 0.9288 - val_loss: 0.2693\n",
      "Epoch 8/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9177 - loss: 0.2931  \n",
      "Epoch 8: val_accuracy did not improve from 0.93470\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 57ms/step - accuracy: 0.9177 - loss: 0.2931 - val_accuracy: 0.9302 - val_loss: 0.2638\n",
      "Epoch 9/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9160 - loss: 0.2956  \n",
      "Epoch 9: val_accuracy improved from 0.93470 to 0.93510, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints6/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 60ms/step - accuracy: 0.9160 - loss: 0.2956 - val_accuracy: 0.9351 - val_loss: 0.2572\n",
      "Epoch 10/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9171 - loss: 0.2955  \n",
      "Epoch 10: val_accuracy did not improve from 0.93510\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 59ms/step - accuracy: 0.9171 - loss: 0.2955 - val_accuracy: 0.9322 - val_loss: 0.2654\n",
      "Epoch 11/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9166 - loss: 0.2942  \n",
      "Epoch 11: val_accuracy did not improve from 0.93510\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 60ms/step - accuracy: 0.9166 - loss: 0.2942 - val_accuracy: 0.9296 - val_loss: 0.2597\n",
      "Epoch 12/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9172 - loss: 0.2948      \n",
      "Epoch 12: val_accuracy did not improve from 0.93510\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4009s\u001b[0m 1s/step - accuracy: 0.9172 - loss: 0.2948 - val_accuracy: 0.9317 - val_loss: 0.2613\n",
      "Epoch 13/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9171 - loss: 0.2971  \n",
      "Epoch 13: val_accuracy improved from 0.93510 to 0.93530, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints6/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 56ms/step - accuracy: 0.9171 - loss: 0.2971 - val_accuracy: 0.9353 - val_loss: 0.2560\n",
      "Epoch 14/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9170 - loss: 0.2953  \n",
      "Epoch 14: val_accuracy did not improve from 0.93530\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 56ms/step - accuracy: 0.9170 - loss: 0.2953 - val_accuracy: 0.9316 - val_loss: 0.2659\n",
      "Epoch 15/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9166 - loss: 0.2981  \n",
      "Epoch 15: val_accuracy did not improve from 0.93530\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 55ms/step - accuracy: 0.9166 - loss: 0.2981 - val_accuracy: 0.9320 - val_loss: 0.2634\n",
      "Epoch 16/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9172 - loss: 0.2950  \n",
      "Epoch 16: val_accuracy did not improve from 0.93530\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 54ms/step - accuracy: 0.9172 - loss: 0.2950 - val_accuracy: 0.9313 - val_loss: 0.2690\n",
      "Epoch 17/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9180 - loss: 0.2932  \n",
      "Epoch 17: val_accuracy did not improve from 0.93530\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 56ms/step - accuracy: 0.9180 - loss: 0.2932 - val_accuracy: 0.9323 - val_loss: 0.2651\n",
      "Epoch 18/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9161 - loss: 0.3021  \n",
      "Epoch 18: val_accuracy did not improve from 0.93530\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 56ms/step - accuracy: 0.9161 - loss: 0.3021 - val_accuracy: 0.9328 - val_loss: 0.2607\n",
      "Epoch 19/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9166 - loss: 0.2972  \n",
      "Epoch 19: val_accuracy improved from 0.93530 to 0.93540, saving model to /Users/tony/Documents/research_projects/aiGenerated/model/checkpoints6/cp.weights.h5\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 56ms/step - accuracy: 0.9166 - loss: 0.2972 - val_accuracy: 0.9354 - val_loss: 0.2594\n",
      "Epoch 20/20\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9167 - loss: 0.2987  \n",
      "Epoch 20: val_accuracy did not improve from 0.93540\n",
      "\u001b[1m2813/2813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 56ms/step - accuracy: 0.9167 - loss: 0.2987 - val_accuracy: 0.9312 - val_loss: 0.2673\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = hybrid_cnn_transformer()\n",
    "model.load_weights(\"/Users/tony/Documents/research_projects/aiGenerated/model/checkpoints5/cp.weights.h5\")\n",
    "\n",
    "def gradual_unfreezing(model,train_generator,validation_generator):\n",
    "    \"\"\"Gradually  unfreeze and retrain layers\"\"\"\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for i in range(len(model.layers)-1,-1,-1):\n",
    "        print(f\"Unfreezing layer: {model.layers[i].name}\")\n",
    "        model.layers[i].trainable = True\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.00001,clipnorm = 1.0),\n",
    "        loss = \"categorical_crossentropy\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = 20,\n",
    "    batch_size = 16,\n",
    "    validation_data = validation_generator,\n",
    "    callbacks = [callbacks,cp_callback]\n",
    ")\n",
    "    return model\n",
    "model = gradual_unfreezing(model,train_generator,validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f911b23e-7b92-4275-a7d1-618306f3d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5000/5000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step\n",
      "Predidcted classes: [1 1 1 1 1 1 1 1 1 0]\n",
      "True classes: [1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on the test\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions,axis =1)\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "print(\"Predidcted classes:\",predicted_classes[-10:])\n",
    "print(\"True classes:\",true_classes[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd16a70-83e3-4ed0-8be1-a20ae1283d3c",
   "metadata": {},
   "source": [
    "# *Metrics Evaluation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5afd5a5e-26a1-4184-a921-c4e82833e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9314\n",
      "Precision: 0.9319230761221068\n",
      "Recall: 0.9313792243739714\n",
      "Jaccard Score 0.8715736606204327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, log_loss, jaccard_score\n",
    "print(f\"Accuracy: {accuracy_score(true_classes,predicted_classes)}\")\n",
    "print(f\"Precision: {precision_score(true_classes,predicted_classes,average = \"weighted\")}\")\n",
    "print(f\"Recall: {f1_score(true_classes,predicted_classes,average = \"weighted\")}\")\n",
    "print(f\"Jaccard Score {jaccard_score(true_classes,predicted_classes,average=\"weighted\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e990856-8e8e-4b53-ad45-6459ef419fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
